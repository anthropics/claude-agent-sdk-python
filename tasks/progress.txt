## Codebase Patterns
- Use FastAPI for webhook servers with signature verification
- All exceptions should use `raise ... from e` pattern for proper exception chaining (ruff B904)
- Use `hmac.compare_digest()` for constant-time signature comparison to prevent timing attacks
- Load configuration from environment variables using a dataclass with `@classmethod from_env()`
- Use explicit type annotations when extracting values from JSON to satisfy mypy (e.g., `token: str = data["token"]`)
- Use httpx.AsyncClient for async HTTP requests
- Use `yaml.safe_load()` for secure YAML parsing (never `yaml.load()` without Loader)
- GitHub Contents API: use `Accept: application/vnd.github.raw+json` to get raw file content
- Webhook handler should fetch config dynamically per request using installation token and head SHA
- Use Protocol for typing queue interfaces, don't inherit ABC for concrete implementations (ruff B024)
- Job ID pattern: `{repo_full_name}#{pr_number}#{reviewer_username}` for unique (PR, reviewer) identification
- Duplicate detection should only consider QUEUED and IN_PROGRESS jobs, not COMPLETED/FAILED (allow re-queueing)
- Use `contextlib.suppress()` instead of try-except-pass (ruff SIM105)
- PRLockManager for PR-level locking: creates/cleans up asyncio.Lock per PR key
- TransientError exception class to distinguish retryable errors from non-retryable ones
- QueueWorker uses exponential backoff with RetryConfig dataclass
- PR context: use pagination for commits/files endpoints (GitHub limits to 100 per page)
- Use asyncio.gather for parallel API requests when fetching independent data
- Claude SDK: use `query()` function for one-shot review generation, collect TextBlocks from AssistantMessage
- For structured JSON output from Claude: use regex to extract JSON from markdown code blocks or find raw JSON braces
- Custom exceptions hierarchy: ClaudeIntegrationError as base, ClaudeSDKError for SDK errors, ReviewParseError for parsing
- Use PromptConfig dataclass to configure prompt building behavior (include_commit_history, max_diff_lines, include_file_stats)
- Use template strings with named placeholders for modular prompt construction
- Parse unified diff patches with hunk headers: `@@ -start,count +start,count @@`
- Use `_variable` naming for unused loop variables to satisfy ruff B007
- Combine nested `if` statements using `and` (ruff SIM102)
- For diff line mapping: track (line_type, old_line, new_line) tuples in hunks
- GitHub PR Review API: POST to `/repos/{owner}/{repo}/pulls/{pr_number}/reviews` with body, event, commit_id, and comments array
- Review event types: APPROVE, REQUEST_CHANGES, COMMENT (must be uppercase for GitHub API)
- Rate limit headers: x-ratelimit-limit, x-ratelimit-remaining, x-ratelimit-reset, x-ratelimit-used
- Handle secondary rate limits via retry-after header on 403 responses
- Use exponential backoff for 5xx server errors with retry logic

---

## 2026-01-24 - US-012
- What was implemented: Module to post complete PR reviews to GitHub including summary body, inline comments, and review state
- Files changed:
  - `tasks/ai_pr_reviewer/github_review.py` - GitHubReviewError, GitHubRateLimitError, ReviewComment, PostedReview, RateLimitInfo dataclasses, post_review(), get_rate_limit_status(), check_rate_limit_before_review() functions
- **Learnings for future iterations:**
  - GitHub PR Review API requires commit_id (the HEAD SHA) to associate comments with correct file versions
  - The comments array must include path, line, body, and side fields for inline comments
  - Multi-line comments use start_line and start_side in addition to line and side
  - Rate limiting: 403 with x-ratelimit-remaining=0 means primary rate limit hit; 403 with retry-after header means secondary (abuse) limit
  - The /rate_limit endpoint returns structured data in resources.core for API rate limits
  - Use asyncio.sleep() with slight buffer (+1 second) after rate limit resets for safety
  - Validation errors return 422 with an errors array containing message fields

---

## 2026-01-24 - US-011
- What was implemented: Inline comment generation module for mapping Claude's suggestions to GitHub's review API format
- Files changed:
  - `tasks/ai_pr_reviewer/inline_comments.py` - DiffHunk dataclass, MappedInlineComment dataclass, parse_diff_hunks(), map_inline_comment(), format_suggestion_block(), normalize_inline_comment()
- **Learnings for future iterations:**
  - GitHub PR review API uses `path` (filename), `line` (line number in diff), and `side` (RIGHT for new lines, LEFT for old lines)
  - Parse unified diff hunk headers with regex: `^@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@`
  - Track line numbers by type: `+` lines have new_line only, `-` lines have old_line only, context lines have both
  - Handle ```suggestion blocks by appending them to the comment body
  - Validate that line numbers are actually in the diff before attempting to post
  - find_closest_valid_line() helps recover from slightly off line numbers
  - normalize_inline_comment() extracts embedded ```suggestion blocks from body text
  - File path matching should be case-insensitive and handle partial paths (suffix matching)

---

## 2026-01-24 - US-010
- What was implemented: Markdown review summary generation from Claude's review output
- Files changed:
  - `tasks/ai_pr_reviewer/review_summary.py` - ReviewSummary dataclass, generate_review_summary() function, ASSESSMENT_LABELS and ASSESSMENT_ICONS constants
- **Learnings for future iterations:**
  - Use dictionary constants for mapping assessment codes to human-readable labels and icons
  - ReviewSummary dataclass holds both the formatted markdown and metadata (persona username, assessment)
  - Format sections as separate functions for modularity: _format_persona_header, _format_assessment_section, _format_summary_section, _format_key_findings_section
  - Key findings section is conditionally included only if there are findings
  - Persona header format: "## :robot: Review on behalf of @{username}"

---

## 2026-01-24 - US-009
- What was implemented: Modular review prompt construction with base template and customization
- Files changed:
  - `tasks/ai_pr_reviewer/prompt_builder.py` - PromptConfig dataclass, BASE_REVIEW_TEMPLATE, build_review_prompt() and helper functions
  - `tasks/ai_pr_reviewer/claude_integration.py` - Updated to delegate prompt building to prompt_builder module
- **Learnings for future iterations:**
  - Use named placeholders in template strings for maintainable prompt construction
  - PromptConfig dataclass allows optional behavior configuration (truncation, stats, commit history)
  - Language injection appends to custom instructions when reviewer has language preference set
  - Separate diff formatting handles binary files, truncation, and optional stats per file
  - Commit history is formatted as single-line summary with abbreviated SHA
  - Keep base template as module constant for visibility and easy modification

---

## 2026-01-24 - US-008
- What was implemented: Claude Code Python SDK integration for AI-powered code review generation
- Files changed:
  - `tasks/ai_pr_reviewer/claude_integration.py` - InlineComment, ReviewOutput dataclasses, generate_review() function, review processor factory
- **Learnings for future iterations:**
  - Use `query()` function for one-shot interactions (simpler than ClaudeSDKClient for this use case)
  - AssistantMessage contains a list of ContentBlock (TextBlock, ToolUseBlock, etc.)
  - ResultMessage indicates completion - check `is_error` for failures and `total_cost_usd` for cost tracking
  - Claude returns structured JSON in markdown code blocks - use regex to extract JSON content
  - Build comprehensive prompts with PR metadata, commit history, and file diffs for context
  - Separate error types: ClaudeSDKError (SDK/connection issues) vs ReviewParseError (response parsing)
  - Cast `re.findall()` match results to `str()` to satisfy mypy's no-any-return check
  - ReviewOutput structure: summary, overall_assessment, key_findings, inline_comments for GitHub review

---

## 2026-01-24 - US-007
- What was implemented: PR context gathering module to fetch full PR information from GitHub API
- Files changed:
  - `tasks/ai_pr_reviewer/pr_context.py` - PRMetadata, PRCommit, FileChange, PRContext dataclasses and fetch functions
- **Learnings for future iterations:**
  - GitHub PR API endpoints: `/pulls/{number}` for metadata, `/pulls/{number}/commits` for commits, `/pulls/{number}/files` for files with diffs
  - Both commits and files endpoints are paginated (max 100 per page) - must loop with `page` parameter
  - File diffs are in the `patch` field - may be None for binary files
  - Renamed files have `previous_filename` field to track the old name
  - Use `asyncio.gather()` to fetch metadata, commits, and files in parallel for efficiency
  - PRContext dataclass with computed properties (`total_additions`, `total_deletions`) for convenient access

---

## 2026-01-24 - US-006
- What was implemented: Background queue worker with PR-level locking and retry logic
- Files changed:
  - `tasks/ai_pr_reviewer/queue_worker.py` - QueueWorker class, PRLockManager, RetryConfig, TransientError, ReviewProcessorProtocol
- **Learnings for future iterations:**
  - Use Protocol for ReviewProcessorProtocol to define the interface for review processing
  - PRLockManager uses a dict of asyncio.Lock objects keyed by `{repo}#{pr_number}` for per-PR locking
  - Track lock usage counts to clean up locks when no longer needed (prevents memory growth)
  - TransientError allows callers to signal retryable failures vs permanent failures
  - RetryConfig dataclass with exponential backoff: `delay = initial * (multiplier ** attempt)` capped at max_delay
  - Worker loop polls queue at configurable interval when empty
  - Recursive _process_job call for retries (already holds lock, just retry the processor call)
  - Use `contextlib.suppress(asyncio.CancelledError)` instead of try-except-pass pattern

---

## 2026-01-24 - US-005
- What was implemented: Review queue with FIFO ordering, duplicate detection, and job status tracking
- Files changed:
  - `tasks/ai_pr_reviewer/review_queue.py` - JobStatus enum, ReviewJob dataclass, generate_job_id() function, ReviewQueueProtocol and InMemoryReviewQueue class
- **Learnings for future iterations:**
  - Use Protocol for defining queue interface, concrete class for implementation (no ABC inheritance)
  - Job ID should be deterministic based on (repo, PR number, reviewer) to enable duplicate detection
  - Store jobs by ID in dict for O(1) lookup, use deque for FIFO queue order
  - Duplicate detection only blocks QUEUED/IN_PROGRESS jobs - completed/failed can be re-queued
  - The dequeue operation atomically removes from queue and marks as IN_PROGRESS
  - clear_completed() method helps manage memory by removing finished jobs

---

## 2026-01-24 - US-004
- What was implemented: Review trigger detection to identify when configured AI reviewers are requested
- Files changed:
  - `tasks/ai_pr_reviewer/trigger_detection.py` - ReviewTrigger and TriggerDetectionResult dataclasses, detect_review_triggers() and helper functions
  - `tasks/ai_pr_reviewer/webhook.py` - Updated handle_pull_request_event() to integrate with reviewer config and trigger detection
- **Learnings for future iterations:**
  - GitHub review_requested webhook includes a single `requested_reviewer` object (not a list) for individual requests
  - The webhook handler flow: authenticate -> fetch config -> detect triggers -> return result
  - Use dataclasses with properties (e.g., `has_triggers`) to provide convenient helper methods
  - Separate trigger detection logic from webhook handling for testability and reuse
  - Return structured response with both triggered reviews and ignored reviewers for transparency

---

## 2026-01-24 - US-003
- What was implemented: Reviewer configuration parser for .ai-reviewer.yml files
- Files changed:
  - `tasks/ai_pr_reviewer/reviewer_config.py` - ReviewerSettings, RepoReviewerConfig dataclasses, parse_reviewer_config() and fetch_reviewer_config() functions
- **Learnings for future iterations:**
  - Use `yaml.safe_load()` for secure YAML parsing (never use `yaml.load()` without Loader)
  - GitHub Contents API returns raw file content when using `Accept: application/vnd.github.raw+json` header
  - Required types-PyYAML for mypy type checking with PyYAML
  - YAML config structure: `reviewers:` section with username keys mapping to `prompt` (required) and `language` (optional)
  - Custom exceptions (ConfigNotFoundError, ConfigParseError) help distinguish between missing files and invalid content

---

## 2026-01-24 - US-002
- What was implemented: GitHub App authentication with JWT generation and installation token management
- Files changed:
  - `tasks/ai_pr_reviewer/github_auth.py` - GitHubAppAuth class with JWT generation, installation token retrieval, and caching
- **Learnings for future iterations:**
  - GitHub App JWT requires RS256 algorithm with private key
  - JWT payload needs `iat` (issued at, 60s in past for clock drift), `exp` (expires in 10 min max), `iss` (app ID)
  - Installation tokens are obtained by POSTing to `/app/installations/{id}/access_tokens` with JWT auth
  - GitHub returns token expiration in ISO 8601 format with "Z" suffix (needs conversion to +00:00 for fromisoformat)
  - Use explicit type annotations like `token: str = data["token"]` to satisfy mypy when extracting from JSON response (avoids `Any` return type)
  - PyJWT library's `jwt.encode()` returns a string directly (not bytes in newer versions)
  - Use httpx.AsyncClient for async HTTP requests to GitHub API

---

## 2026-01-24 - US-001
- What was implemented: GitHub App webhook server with FastAPI
- Files changed:
  - `tasks/ai_pr_reviewer/__init__.py` - Package init
  - `tasks/ai_pr_reviewer/config.py` - AppConfig dataclass for environment-based configuration
  - `tasks/ai_pr_reviewer/webhook.py` - FastAPI server with /webhook and /health endpoints
  - `tasks/ai_pr_reviewer/py.typed` - PEP 561 marker for typed package
- **Learnings for future iterations:**
  - Use `from e` pattern when re-raising exceptions (ruff B904 check)
  - GitHub webhook signature format is `sha256=<hex_digest>`
  - FastAPI Header() parameters automatically convert header names (X-Hub-Signature-256 -> x_hub_signature_256)

---
