## Codebase Patterns
- Use FastAPI for webhook servers with signature verification
- All exceptions should use `raise ... from e` pattern for proper exception chaining (ruff B904)
- Use `hmac.compare_digest()` for constant-time signature comparison to prevent timing attacks
- Load configuration from environment variables using a dataclass with `@classmethod from_env()`
- Use explicit type annotations when extracting values from JSON to satisfy mypy (e.g., `token: str = data["token"]`)
- Use httpx.AsyncClient for async HTTP requests
- Use `yaml.safe_load()` for secure YAML parsing (never `yaml.load()` without Loader)
- GitHub Contents API: use `Accept: application/vnd.github.raw+json` to get raw file content
- Webhook handler should fetch config dynamically per request using installation token and head SHA
- Use Protocol for typing queue interfaces, don't inherit ABC for concrete implementations (ruff B024)
- Job ID pattern: `{repo_full_name}#{pr_number}#{reviewer_username}` for unique (PR, reviewer) identification
- Duplicate detection should only consider QUEUED and IN_PROGRESS jobs, not COMPLETED/FAILED (allow re-queueing)
- Use `contextlib.suppress()` instead of try-except-pass (ruff SIM105)
- PRLockManager for PR-level locking: creates/cleans up asyncio.Lock per PR key
- TransientError exception class to distinguish retryable errors from non-retryable ones
- QueueWorker uses exponential backoff with RetryConfig dataclass
- PR context: use pagination for commits/files endpoints (GitHub limits to 100 per page)
- Use asyncio.gather for parallel API requests when fetching independent data

---

## 2026-01-24 - US-007
- What was implemented: PR context gathering module to fetch full PR information from GitHub API
- Files changed:
  - `tasks/ai_pr_reviewer/pr_context.py` - PRMetadata, PRCommit, FileChange, PRContext dataclasses and fetch functions
- **Learnings for future iterations:**
  - GitHub PR API endpoints: `/pulls/{number}` for metadata, `/pulls/{number}/commits` for commits, `/pulls/{number}/files` for files with diffs
  - Both commits and files endpoints are paginated (max 100 per page) - must loop with `page` parameter
  - File diffs are in the `patch` field - may be None for binary files
  - Renamed files have `previous_filename` field to track the old name
  - Use `asyncio.gather()` to fetch metadata, commits, and files in parallel for efficiency
  - PRContext dataclass with computed properties (`total_additions`, `total_deletions`) for convenient access

---

## 2026-01-24 - US-006
- What was implemented: Background queue worker with PR-level locking and retry logic
- Files changed:
  - `tasks/ai_pr_reviewer/queue_worker.py` - QueueWorker class, PRLockManager, RetryConfig, TransientError, ReviewProcessorProtocol
- **Learnings for future iterations:**
  - Use Protocol for ReviewProcessorProtocol to define the interface for review processing
  - PRLockManager uses a dict of asyncio.Lock objects keyed by `{repo}#{pr_number}` for per-PR locking
  - Track lock usage counts to clean up locks when no longer needed (prevents memory growth)
  - TransientError allows callers to signal retryable failures vs permanent failures
  - RetryConfig dataclass with exponential backoff: `delay = initial * (multiplier ** attempt)` capped at max_delay
  - Worker loop polls queue at configurable interval when empty
  - Recursive _process_job call for retries (already holds lock, just retry the processor call)
  - Use `contextlib.suppress(asyncio.CancelledError)` instead of try-except-pass pattern

---

## 2026-01-24 - US-005
- What was implemented: Review queue with FIFO ordering, duplicate detection, and job status tracking
- Files changed:
  - `tasks/ai_pr_reviewer/review_queue.py` - JobStatus enum, ReviewJob dataclass, generate_job_id() function, ReviewQueueProtocol and InMemoryReviewQueue class
- **Learnings for future iterations:**
  - Use Protocol for defining queue interface, concrete class for implementation (no ABC inheritance)
  - Job ID should be deterministic based on (repo, PR number, reviewer) to enable duplicate detection
  - Store jobs by ID in dict for O(1) lookup, use deque for FIFO queue order
  - Duplicate detection only blocks QUEUED/IN_PROGRESS jobs - completed/failed can be re-queued
  - The dequeue operation atomically removes from queue and marks as IN_PROGRESS
  - clear_completed() method helps manage memory by removing finished jobs

---

## 2026-01-24 - US-004
- What was implemented: Review trigger detection to identify when configured AI reviewers are requested
- Files changed:
  - `tasks/ai_pr_reviewer/trigger_detection.py` - ReviewTrigger and TriggerDetectionResult dataclasses, detect_review_triggers() and helper functions
  - `tasks/ai_pr_reviewer/webhook.py` - Updated handle_pull_request_event() to integrate with reviewer config and trigger detection
- **Learnings for future iterations:**
  - GitHub review_requested webhook includes a single `requested_reviewer` object (not a list) for individual requests
  - The webhook handler flow: authenticate -> fetch config -> detect triggers -> return result
  - Use dataclasses with properties (e.g., `has_triggers`) to provide convenient helper methods
  - Separate trigger detection logic from webhook handling for testability and reuse
  - Return structured response with both triggered reviews and ignored reviewers for transparency

---

## 2026-01-24 - US-003
- What was implemented: Reviewer configuration parser for .ai-reviewer.yml files
- Files changed:
  - `tasks/ai_pr_reviewer/reviewer_config.py` - ReviewerSettings, RepoReviewerConfig dataclasses, parse_reviewer_config() and fetch_reviewer_config() functions
- **Learnings for future iterations:**
  - Use `yaml.safe_load()` for secure YAML parsing (never use `yaml.load()` without Loader)
  - GitHub Contents API returns raw file content when using `Accept: application/vnd.github.raw+json` header
  - Required types-PyYAML for mypy type checking with PyYAML
  - YAML config structure: `reviewers:` section with username keys mapping to `prompt` (required) and `language` (optional)
  - Custom exceptions (ConfigNotFoundError, ConfigParseError) help distinguish between missing files and invalid content

---

## 2026-01-24 - US-002
- What was implemented: GitHub App authentication with JWT generation and installation token management
- Files changed:
  - `tasks/ai_pr_reviewer/github_auth.py` - GitHubAppAuth class with JWT generation, installation token retrieval, and caching
- **Learnings for future iterations:**
  - GitHub App JWT requires RS256 algorithm with private key
  - JWT payload needs `iat` (issued at, 60s in past for clock drift), `exp` (expires in 10 min max), `iss` (app ID)
  - Installation tokens are obtained by POSTing to `/app/installations/{id}/access_tokens` with JWT auth
  - GitHub returns token expiration in ISO 8601 format with "Z" suffix (needs conversion to +00:00 for fromisoformat)
  - Use explicit type annotations like `token: str = data["token"]` to satisfy mypy when extracting from JSON response (avoids `Any` return type)
  - PyJWT library's `jwt.encode()` returns a string directly (not bytes in newer versions)
  - Use httpx.AsyncClient for async HTTP requests to GitHub API

---

## 2026-01-24 - US-001
- What was implemented: GitHub App webhook server with FastAPI
- Files changed:
  - `tasks/ai_pr_reviewer/__init__.py` - Package init
  - `tasks/ai_pr_reviewer/config.py` - AppConfig dataclass for environment-based configuration
  - `tasks/ai_pr_reviewer/webhook.py` - FastAPI server with /webhook and /health endpoints
  - `tasks/ai_pr_reviewer/py.typed` - PEP 561 marker for typed package
- **Learnings for future iterations:**
  - Use `from e` pattern when re-raising exceptions (ruff B904 check)
  - GitHub webhook signature format is `sha256=<hex_digest>`
  - FastAPI Header() parameters automatically convert header names (X-Hub-Signature-256 -> x_hub_signature_256)

---
